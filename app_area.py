# app_area.py ‚Äî Painel por √Årea
import streamlit as st
import pandas as pd
import plotly.express as px
from pathlib import Path
import networkx as nx
from pyvis.network import Network

from wordcloud import WordCloud

# ==========================================================
# üß† FUN√á√ïES CACHEADAS
# ==========================================================

@st.cache_data(show_spinner=False)
def load_csv_cached(path: str) -> pd.DataFrame:
    """L√™ CSV e guarda em cache"""
    return pd.read_csv(path)

@st.cache_data(show_spinner=False)
def load_cached_html(html_path: str) -> str | None:
    """Carrega HTML pr√©-gerado do grafo (PyVis) se existir."""
    p = Path(html_path)
    if p.exists():
        return p.read_text(encoding="utf-8")
    return None

@st.cache_data(show_spinner=False)
def load_html_sankey_cached(path: str) -> str:
    """L√™ e cacheia o HTML do Sankey"""
    return open(path, encoding="utf-8").read()

# ==========================================================
# üß© FUN√á√ÉO PRINCIPAL
# ==========================================================
def run(area_sel: str, df_filtrado: pd.DataFrame):
    # ======================== IO ============================    
    INST_PATH     = "bases/select_instituicoes_por_inct.csv"
    PROD_BBL_PATH = "bases/big_number_qtd_producao_bibliografica_periodo_area.csv"
    MAIOR_FORMACAO_PATH = "bases/big_number_maior_formacao.csv"
    PALAVRAS_WORDCLOUD_PATH = "bases/wordcloud_area_agg.csv"
    PATH_GRAD = "bases/grafico_maior_graduacao_area.csv"
    TEXTO_PATH = "bases/texto_descricao_area.csv"
    
    df_inst  = load_csv_cached(INST_PATH)
    prod_bbl = load_csv_cached(PROD_BBL_PATH)
    maior_formacoes = load_csv_cached(MAIOR_FORMACAO_PATH)
    df_wc_area_agg = load_csv_cached(PALAVRAS_WORDCLOUD_PATH)
    df_grad = load_csv_cached(PATH_GRAD)
    df_texto_area = load_csv_cached(TEXTO_PATH)
    
    info = df_filtrado.iloc[0]
    

    # ====== FILTRO DE PER√çODO ======
    periodos = ["2010‚Äì2015", "2015‚Äì2020", "2020‚Äì2025"]
    periodo_sel = st.radio(
        "Per√≠odo:",
        options=periodos,
        index=len(periodos) - 1,  # come√ßa no mais recente
        horizontal=True,
        key=f"periodo_{area_sel}"
    )

    st.markdown(f"## Painel ‚Äî √Årea: {area_sel}")

    st.markdown("""**CONTEXTUALIZA√á√ÉO METODOL√ìGICA**    
O estudo se baseia na premissa de que a estrutura das intera√ß√µes entre cientistas √© fundamental para entender as redes de colabora√ß√£o cient√≠fica. Utilizando a abordagem de redes, os cientistas s√£o representados como "n√≥s" e as coautorias como "arestas", permitindo mapear a organiza√ß√£o social da ci√™ncia. Conforme demonstrado por Newman (2001), essas redes formam "mundos pequenos" com alta conectividade, o que impacta diretamente a difus√£o de informa√ß√µes e a inova√ß√£o.    
Para investigar o conte√∫do dessa produ√ß√£o, a metodologia aplica a an√°lise de redes sem√¢nticas. Esse m√©todo √© usado para extrair, correlacionar e visualizar o significado das rela√ß√µes e conceitos na literatura cient√≠fica. O objetivo √© identificar insights (sinais fracos e fortes) que possam auxiliar na avalia√ß√£o de pol√≠ticas p√∫blicas e na tomada de decis√£o para os INCTs.
""")
    texto = df_texto_area.query(
        "area == @area_sel and periodo == @periodo_sel"
    )["texto_md"].iloc[0]
    
    st.markdown(texto)
    texto_coautoria = df_texto_area.query(
        "area == @area_sel and periodo == @periodo_sel"
    )["texto_coautoria"].iloc[0]
    st.markdown(texto_coautoria)

    # ==========================================================
    # üï∏Ô∏è GRAFO INTERATIVO (GEXF CACHEADO)
    # ==========================================================
    # path_gexf = info.get("path_area_gexf_html", "")
    # html_cached_path = f"gexf_html/{Path(path_gexf).stem}.html"
    # with st.container(border=True):
    #     st.markdown("#### Rede de Colabora√ß√£o")
    #     html = load_cached_html(html_cached_path)
    #     if html:
    #         st.components.v1.html(
    #             #html,
    #             f"""
    #             <iframe srcdoc='{html.replace("'", "&apos;")}'
    #                     style="width:100%; height:950px; border:none; overflow:hidden;">
    #             </iframe>
    #             """,
    #             height=900,
    #             scrolling=False
    #         )
    #     else:
    #         st.info(
    #             "üìÅ Grafo da √°rea ainda n√£o foi pr√©-gerado. "
    #             f"Esperado: `{html_cached_path}`"
    #         )

    # ==========================================================
    # ü™¢ FLUXO SANKEY (CACHEADO)
    # ==========================================================
    st.subheader("Fluxo Sankey ‚Äî Palavras-chave por Per√≠odo")

    sankey_path = Path(f"sankey_inct_palavra_tratada_area/sankey_inct_{info['identificador_area']}.html")

    with st.container(border=True):
        if sankey_path.exists():
            try:
                html = load_html_sankey_cached(sankey_path)
                sankey_html = f"""
                <div style="
                        width: 100%;
                        overflow-x: auto;
                        padding: 10px;
                        background-color: #fff;
                        text-align: center;
                        ">
                    <div style="
                        display: inline-block;
                        min-width: 900px;
                        width: max-content;
                    ">
                    {html}</div>
                </div>
                """
                st.components.v1.html(sankey_html, height=1000, scrolling=False)
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erro ao carregar o gr√°fico Sankey: {e}")
        else:
            st.info("Nenhum gr√°fico Sankey dispon√≠vel para esta √°rea.")

    # ==========================================================
    # üìä KPIs iniciais
    # ==========================================================
    st.divider()
    n_incts = len(df_filtrado)
    total_pesquisadores = int(df_filtrado["n_pesquisadores"].sum())
    fem = int(df_filtrado["n_feminino"].sum())
    masc = int(df_filtrado["n_masculino"].sum())
    pct_fem = (fem / total_pesquisadores * 100) if total_pesquisadores else 0.0
    pct_masc = (masc / total_pesquisadores * 100) if total_pesquisadores else 0.0

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("INCTs nesta √°rea", n_incts)
    col2.metric("Pesquisadores totais", total_pesquisadores)
    col3.metric("Feminino (%)", f"{pct_fem:.1f}%")
    col4.metric("Masculino (%)", f"{pct_masc:.1f}%")

    # ==========================================================
    # üìÑ TABELA DE INFORMA√á√ïES POR √ÅREA
    # ==========================================================
    st.divider()
    st.subheader("Informa√ß√µes dos INCTs desta √Årea")
    
    
    # Tooltip explicativo
    st.markdown(
        """
        <span style='font-size: 13px; color: gray;'>
        ‚ÑπÔ∏è <strong>Aten√ß√£o:</strong> A soma entre pesquisadores do sexo feminino e masculino 
        pode n√£o corresponder exatamente ao total de pesquisadores, 
        pois alguns curr√≠culos n√£o possuem o campo de sexo preenchido.
        </span>
        """,
        unsafe_allow_html=True
    )
    
    # Sele√ß√£o das colunas necess√°rias
    df_tabela = df_filtrado[[
        "nome_inct",
        "n_pesquisadores",
        "n_feminino",
        "n_masculino"
    ]].rename(columns={
        "nome_inct": "INCT",
        "n_pesquisadores": "Quantidade de Pesquisadores",
        "n_feminino": "Feminino",
        "n_masculino": "Masculino",
    })
    
    # Ordena√ß√£o opcional (maior ‚Üí menor)
    df_tabela = df_tabela.sort_values("Quantidade de Pesquisadores", ascending=False)
    
    # Estilo da tabela (mais bonita)
    st.dataframe(
        df_tabela,
        width="stretch",
        hide_index=True
    )

    # ======================== KPIs: PRODU√á√ÉO BIBLIOGR√ÅFICA ===================
    st.divider()
    st.markdown("### Produ√ß√£o Bibliogr√°fica por Per√≠odo")
    
    import unicodedata
    
    def normalize_text(text):
        """Remove acentos, normaliza h√≠fen e deixa em min√∫sculas."""
        if pd.isna(text):
            return ""
        text = str(text).strip().lower()
        text = unicodedata.normalize("NFKC", text)
        text = text.replace("‚Äì", "-")  # troca h√≠fen especial por simples
        return text
    
    def get_val(df, tipo, periodo):
        """Busca o valor de produ√ß√£o de forma robusta (tolerante a varia√ß√µes)."""
        if df.empty:
            return 0
        tipo_norm = normalize_text(tipo)
        periodo_norm = normalize_text(periodo)
        df["tipo_norm"] = df["tipo_producao"].apply(normalize_text)
        df["periodo_norm"] = df["periodo"].apply(normalize_text)
        val = df.query("tipo_norm == @tipo_norm and periodo_norm == @periodo_norm")["n_tipos_producao"]
        return int(val.iloc[0]) if not val.empty else 0
    
    
    tipos = [
        ("Artigos Publicados",               "Artigo Publicado"),
        ("Trabalhos em Eventos",             "Trabalho Em Eventos"),
        ("Cap√≠tulos de Livros",              "Capitulo De Livro Publicado"),
        ("Livros Publicados/Organizados",    "Livro Publicado Ou Organizado"),
        ("Textos em Jornais/Revistas",       "Texto Em Jornal Ou Revista"),
        ("Outras Produ√ß√µes Bibliogr√°ficas",  "Outra Producao Bibliografica"),
        ("Artigos Aceitos",                  "Artigo Aceito Para Publicacao"),
        ("Pref√°cios/P√≥sf√°cios",              "Prefacio Posfacio"),
        ("Tradu√ß√µes",                        "Traducao"),
        ("Partituras Musicais",              "Partitura Musical"),
    ]
    
    periodos = ["2010-2015", "2015-2020", "2020-2025"]
    
    df_prod_bbl = (
        prod_bbl[prod_bbl["area"] == area_sel].copy()
        if "area" in prod_bbl.columns
        else pd.DataFrame()
    )
    
    # === Layout responsivo: 2 linhas (5 m√©tricas cada) ===
    for periodo in periodos:
        st.markdown(f"### {periodo}")
        
    
        # Divide os 10 tipos em 2 linhas de 5
        for linha in range(0, len(tipos), 5):
            subset = tipos[linha:linha+5]
    
            with st.container(horizontal=True, gap="medium"):
                cols = st.columns(len(subset), gap="medium")
    
                for i, (titulo, tipo) in enumerate(subset):
                    val = get_val(df_prod_bbl, tipo, periodo)
    
                    with cols[i]:
                        st.metric(
                            label=titulo,
                            value=f"{val:,}".replace(",", "."),
                            label_visibility="visible",
                            width="content",
                        )
                        
        # pequeno espa√ßamento entre blocos de per√≠odo
        st.markdown("<br>", unsafe_allow_html=True)
    
    # # ==========================================================
    # # ‚òÅÔ∏è NUVEM DE PALAVRAS
    # # ==========================================================
    # st.divider()
    # st.subheader("Nuvem de Palavras ‚Äî Produ√ß√£o Cient√≠fica da √Årea")
    

    # try:
    #     # df_wc = load_csv_cached("bases/wordcloud.csv")
    #     df_wc_area = df_wc[df_wc["area"] == area_sel]
    #     if not df_wc_area.empty:
    #         top_words = df_wc_area["palavra"].value_counts().head(100)
    #         st.bar_chart(top_words)
    #     else:
    #         st.info("Sem palavras dispon√≠veis para esta √°rea.")
    # except Exception as e:
    #     st.warning(f"Erro ao carregar wordcloud: {e}")
    # ==========================================================
    # ‚òÅÔ∏è NUVEM DE PALAVRAS
    # ==========================================================
    # ==========================================================
    # ‚òÅÔ∏è NUVEM DE PALAVRAS ‚Äî GR√ÅFICO DE BARRAS
    # ==========================================================
    st.divider()
    st.subheader("Distribui√ß√£o de Palavras-Chave")
    
    try:
        # üîπ Seleciona per√≠odos da base agregada
        periodos_wc = sorted(df_wc_area_agg["periodo"].unique())
    
        # üîπ Multiselect
        periodos_sel = st.multiselect(
            "Filtrar por per√≠odo:",
            options=periodos_wc,
            default=periodos_wc
        )
    
        # üîπ Filtra pela √°rea selecionada
        df_area_sel = df_wc_area_agg[df_wc_area_agg["area"] == area_sel]
    
        # üîπ Filtra per√≠odos
        if periodos_sel:
            df_area_sel = df_area_sel[df_area_sel["periodo"].isin(periodos_sel)]
    
        # üîπ Gr√°fico
        if not df_area_sel.empty:
            top_words = (
                df_area_sel.groupby("palavra")["freq"]
                .sum()
                .sort_values(ascending=False)
                .head(100)
            )
            st.bar_chart(top_words, width="stretch")
        else:
            st.info("Sem palavras dispon√≠veis para esta √°rea e per√≠odo selecionado.")
    
    except Exception as e:
        st.warning(f"Erro ao carregar wordcloud: {e}")



    # ====================== CARDS: WORDCLOUD | MAIOR FORMA√á√ÉO ======================
    # ====================== CARDS: WORDCLOUD | MAIOR FORMA√á√ÉO ======================
    import matplotlib
    matplotlib.use("Agg")
    
    col_wc, col_form = st.columns(2, gap="medium")
    
    with col_wc:
        with st.container(border=True):
            st.markdown("#### Nuvem de Palavras")
    
            # üîπ Filtra pela √°rea
            wc_sel = df_wc_area_agg[df_wc_area_agg["area"] == area_sel]
    
            # üîπ Filtrar per√≠odos selecionados
            if periodos_sel:
                wc_sel = wc_sel[wc_sel["periodo"].isin(periodos_sel)]
    
            if wc_sel.empty:
                st.warning("Nenhuma frase dispon√≠vel para gerar a nuvem com os filtros atuais.")
            else:
                s = wc_sel["palavra"].astype(str)
    
                # stopwords b√°sicas
                STOPWORDS_ONEWORD = {
                    "de","da","do","das","dos","em","no","na","nas","nos","para","por",
                    "e","a","o","os","as","um","uma","com","ao","aos","se","que",
                    "sobre","entre","ou","como"
                }
    
                # remove palavras isoladas muito comuns
                mascara_um_termo = ~s.str.contains(r"\s", regex=True)
                palavras_validas = s[~(mascara_um_termo & s.isin(STOPWORDS_ONEWORD))]
    
                # alinhar com a base original
                wc_filtrado = wc_sel.loc[palavras_validas.index]
    
                # dicion√°rio de frequ√™ncias diretamenre da base
                freqs = dict(
                    zip(
                        wc_filtrado["palavra"],
                        wc_filtrado["freq"]
                    )
                )
    
                if not freqs:
                    st.warning("Nenhuma frase dispon√≠vel ap√≥s filtragem.")
                else:
                    top_n = st.slider(
                        "N√∫mero de express√µes exibidas",
                        min_value=10,
                        max_value=300,
                        value=30,
                        step=10,
                        key=f"slider_wc_{area_sel}",
                    )
    
                    # top n ordenado
                    freqs_top = dict(
                        sorted(freqs.items(), key=lambda x: x[1], reverse=True)[:top_n]
                    )
    
                    # gerar wordcloud
                    wc_img = WordCloud(
                        width=900,
                        height=500,
                        background_color="white",
                        colormap="Blues",
                        collocations=False,
                    ).generate_from_frequencies(freqs_top)
    
                    st.image(wc_img.to_array(), width="content")
    

    # ---------- CARD 2: MAIOR FORMA√á√ÉO ----------
    with col_form:
        with st.container(border=True):
            st.markdown(f"#### Maior Forma√ß√£o por √Årea")
    
            df_plot = (
                maior_formacoes[maior_formacoes["area"] == area_sel]
                #.sort_values("qtd", ascending=False)
                # maior_formacoes
                   .groupby(["area", "area_de_maior_formacao"], as_index=False)["count"]
                   .sum()
                   .sort_values("count", ascending=False)
            )
    
            if df_plot.empty:
                st.warning("Nenhuma informa√ß√£o de forma√ß√£o dispon√≠vel para esta √Årea.")
            else:
                fig_bar = px.bar(
                    df_plot,
                    x="count",
                    # y="area_de_maior_formacao",
                    y="area_de_maior_formacao",
                    orientation="h",
                    color="count",
                    color_continuous_scale="Blues",
                    text="count",
                    labels={
                        "count": "Quantidade",
                        "area_de_maior_formacao": "√Årea"
                    },
                )
                fig_bar.update_layout(
                    xaxis_title="N√∫mero de Pesquisadores",
                    yaxis_title="√Årea de Forma√ß√£o",
                    #height=420,
                    height=530,
                    margin=dict(l=10, r=10, t=30, b=0),
                )
                fig_bar.update_traces(textposition="outside")
    
                # Somente config (nada de kwargs antigos) -> sem avisos
                st.plotly_chart(
                    fig_bar,
                    config={
                        "displayModeBar": True,
                        "displaylogo": False,
                        "responsive": True,
                        #"scrollZoom": True,
                        "scrollZoom": False,
                        "doubleClick": "reset",  # padr√£o seguro
                        "modeBarButtonsToRemove": [
                                    "zoom2d", "pan2d", "select2d", "lasso2d", "zoomIn2d",
                                    "zoomOut2d", "resetScale2d" #"autoScale2d",
                                ],
                    },
                )

    # ======================== MAPA + TOP INSTITUI√á√ïES ===================
    col_uf, col_form = st.columns(2, gap="medium")
    with col_uf:
        with st.container(border=True):
            #st.markdown("#### üó∫Ô∏è Distribui√ß√£o Geogr√°fica ‚Äî Pesquisadores por UF")
            st.markdown("#### Distribui√ß√£o do Endere√ßo Profissional por UF")
            
    
            info_instituicao = df_inst[df_inst["area"] == area_sel].copy()
            ufs = [
                "AC","AL","AM","AP","BA","CE","DF","ES","GO","MA","MG","MS","MT",
                "PA","PB","PE","PI","PR","RJ","RN","RO","RR","RS","SC","SE","SP","TO"
            ]
            uf_base = pd.DataFrame({"uf": ufs})
    
            if not info_instituicao.empty:
                uf_counts = (
                    info_instituicao.groupby("uf")["nome_instituicao_empresa"]
                    .count()
                    .reset_index(name="qtd")
                )
            else:
                uf_counts = pd.DataFrame(columns=["uf", "qtd"])
    
            uf_counts = uf_base.merge(uf_counts, on="uf", how="left").fillna(0)
    
            geojson_url = "https://raw.githubusercontent.com/codeforamerica/click_that_hood/master/public/data/brazil-states.geojson"
    
            fig_mapa = px.choropleth(
                uf_counts,
                geojson=geojson_url,
                locations="uf",
                featureidkey="properties.sigla",
                color="qtd",
                hover_name="uf",
                hover_data={"qtd": True},
                #hover_data={"qtd": "Quantidade de Institui√ß√µes/Empresas"},
                color_continuous_scale="Blues",
                range_color=(0, int(uf_counts["qtd"].max()) if len(uf_counts) else 0),
                #title="Distribui√ß√£o do Endere√ßo Profissional por UF",
                labels={
                        "uf": "UF",
                        "qtd": "Quantidade de Institui√ß√µes/Empresas"
                    },
            )
            fig_mapa.update_geos(fitbounds="locations", visible=False, scope="south america")
            fig_mapa.update_layout(
                height=500,
                margin=dict(l=0, r=0, t=40, b=0),
                coloraxis_colorbar=dict(title="Institui√ß√µes"),
                dragmode=False,
            )
    
            # ‚úÖ NENHUM argumento solto ‚Äî tudo via config
            st.plotly_chart(
                fig_mapa,
                config={
                    "displayModeBar": True,
                    "scrollZoom": False,
                    "doubleClick": False,
                    "staticPlot": False,  # mant√©m hover ativo
                    "responsive": True,
                    "plotlyServerURL": "",  # silencia o aviso de kwargs
                },
            )


    # ---------- CARD 2: MAIOR FORMA√á√ÉO ----------
    with col_form:
        with st.container(border=True):
            st.markdown("#### Principais Institui√ß√µes Participantes")
            
    
            if not info_instituicao.empty:
                top_inst = (
                    info_instituicao.groupby("nome_instituicao_empresa")["n_pesquisadores"]
                    .sum()
                    .reset_index()
                    .sort_values("n_pesquisadores", ascending=False)
                    .head(10)
                )
                fig_bar = px.bar(
                    top_inst,
                    x="n_pesquisadores",
                    y="nome_instituicao_empresa",
                    orientation="h",
                    color="n_pesquisadores",
                    color_continuous_scale="Blues",
                    title="Top 10 Institui√ß√µes",
                    #title="Top Institui√ß√µes Participantes",
                    text="n_pesquisadores",
                    labels={
                        "nome_instituicao_empresa": "Nome Institui√ß√£o/Empresa",
                        "n_pesquisadores": "Quantidade de Pesquisadores"
                    },
                )
                fig_bar.update_layout(
                    yaxis=dict(title=""),
                    xaxis_title="N√∫mero de Pesquisadores",
                    height=500,
                    margin=dict(l=0, r=0, t=40, b=0),
                )
    
                st.plotly_chart(
                    fig_bar,
                    config={
                        "displayModeBar": True,
                        "displaylogo": False,
                        "modeBarButtonsToRemove": [
                                    "zoom2d", "pan2d", "select2d", "lasso2d", "zoomIn2d",
                                    "zoomOut2d", "resetScale2d" #"autoScale2d",
                                ],
                        "responsive": True,
                        "scrollZoom": False,
                        "plotlyServerURL": "",
                    },
                )
            else:
                st.warning("Nenhuma institui√ß√£o registrada para esta √Årea.")


    # --- CARD: Gr√°fico de barras verticais (abaixo) ---   
    with st.container(border=True):
        st.markdown("#### Distribui√ß√£o das Forma√ß√µes Mais Altas")
    
        if Path(PATH_GRAD).exists():
            df_plot = (
                df_grad[df_grad["area"] == area_sel]
                .sort_values("qtd", ascending=False)
            )
    
            if df_plot.empty:
                st.warning("Nenhuma informa√ß√£o de forma√ß√£o dispon√≠vel para esta √Årea.")
            else:
                fig_bar_vert = px.bar(
                    df_plot,
                    x="formacao_mais_alta",
                    y="qtd",
                    color="qtd",
                    color_continuous_scale="Blues",
                    text="qtd",
                    #title=f"Distribui√ß√£o das Forma√ß√µes Mais Altas ‚Äî {inct_sel}",
                    labels={
                        "formacao_mais_alta": "Forma√ß√£o mais alta",
                        "qtd": "Pesquisadores"
                    },
                )
                fig_bar_vert.update_layout(
                    xaxis_title="Forma√ß√£o Mais Alta",
                    yaxis_title="N√∫mero de Pesquisadores",
                    height=350,
                    margin=dict(l=20, r=20, t=60, b=80),
                )
                fig_bar_vert.update_traces(textposition="outside", cliponaxis=False)
    
                st.plotly_chart(
                    fig_bar_vert,
                    config={
                        "displayModeBar": True,
                        "scrollZoom": False,
                        "displaylogo": False,
                        "responsive": True,
                        "modeBarButtonsToRemove": [
                                    "zoom2d", "pan2d", "select2d", "lasso2d", "zoomIn2d",
                                    "zoomOut2d", "resetScale2d" #"autoScale2d",
                                ],
                        
                    },
                )
        else:
            st.warning("Base 'grafico_maior_graduacao_area.csv' n√£o encontrada.")
